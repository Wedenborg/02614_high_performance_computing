Loaded module: cuda/10.2
Loaded dependency [gcc/6.3.0]: binutils/2.29
Loaded module: gcc/6.3.0
==5673== NVPROF is profiling process 5673, command: ./matmult_f.nvcc gpu5 500 500 500
==5673== Profiling application: ./matmult_f.nvcc gpu5 500 500 500
  5859.375 172951.108 # matmult_gpu5
==5673== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   52.42%  687.10ms      4153  165.45us  1.5360us  176.54us  [CUDA memcpy HtoD]
                   24.22%  317.40ms      2076  152.89us  152.77us  161.63us  [CUDA memcpy DtoH]
                   23.36%  306.14ms      2076  147.47us  144.19us  163.81us  MatMulKernel
==5690== NVPROF is profiling process 5690, command: ./matmult_f.nvcc gpu5 1000 1000 1000
==5690== Profiling application: ./matmult_f.nvcc gpu5 1000 1000 1000
==5690== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   43.77%  849.92ms      1301  653.28us  1.3760us  664.09us  [CUDA memcpy HtoD]
                   35.85%  696.08ms       650  1.0709ms  1.0579ms  1.0917ms  MatMulKernel
                   20.38%  395.72ms       650  608.80us  608.54us  618.01us  [CUDA memcpy DtoH]
 23437.500 433154.292 # matmult_gpu5
==5707== NVPROF is profiling process 5707, command: ./matmult_f.nvcc gpu5 2000 2000 2000
==5707== Profiling application: ./matmult_f.nvcc gpu5 2000 2000 2000
==5707== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   50.08%  1.25756s       151  8.3282ms  8.2991ms  8.3588ms  MatMulKernel
                   35.32%  886.91ms       303  2.9271ms  1.4080us  3.2775ms  [CUDA memcpy HtoD]
                   14.60%  366.55ms       151  2.4275ms  2.4272ms  2.4313ms  [CUDA memcpy DtoH]
 93750.000 801178.414 # matmult_gpu5
==5732== NVPROF is profiling process 5732, command: ./matmult_f.nvcc gpu5 4000 4000 4000
==5732== Profiling application: ./matmult_f.nvcc gpu5 4000 4000 4000
==5732== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   62.92%  1.84263s        28  65.808ms  65.755ms  65.927ms  MatMulKernel
                   27.80%  814.14ms        57  14.283ms  1.4080us  19.081ms  [CUDA memcpy HtoD]
                    9.28%  271.85ms        28  9.7090ms  9.7087ms  9.7110ms  [CUDA memcpy DtoH]
375000.000 1167487.165 # matmult_gpu5
==5749== NVPROF is profiling process 5749, command: ./matmult_f.nvcc gpu5 8000 8000 8000
==5749== Profiling application: ./matmult_f.nvcc gpu5 8000 8000 8000
==5749== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   77.34%  2.62293s         5  524.59ms  524.50ms  524.72ms  MatMulKernel
                   16.94%  574.36ms        11  52.215ms  1.6000us  81.096ms  [CUDA memcpy HtoD]
                    5.72%  194.14ms         5  38.827ms  38.827ms  38.827ms  [CUDA memcpy DtoH]
1500000.000 1493519.056 # matmult_gpu5

------------------------------------------------------------
Sender: LSF System <lsfadmin@n-62-20-2>
Subject: Job 5179773: <mm_batch> in cluster <dcc> Done

Job <mm_batch> was submitted from host <n-62-20-6> by user <s164548> in cluster <dcc> at Fri Jan 24 14:11:32 2020
Job was executed on host(s) <n-62-20-2>, in queue <hpcintrogpu>, as user <s164548> in cluster <dcc> at Fri Jan 24 14:11:34 2020
</zhome/1c/9/118567> was used as the home directory.
</zhome/1c/9/118567/Matmult> was used as the working directory.
Started at Fri Jan 24 14:11:34 2020
Terminated at Fri Jan 24 14:11:58 2020
Results reported at Fri Jan 24 14:11:58 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
# 02614 - High-Performance Computing, January 2018
# 
# batch script to run matmult on a decidated server in the hpcintro
# queue
#
# Author: Bernd Dammann <bd@cc.dtu.dk>
#
#BSUB -J mm_batch
#BSUB -o mm_batch_%J.out
#BSUB -q hpcintrogpu
#BSUB -n 1
#BSUB -gpu "num=1:mode=exclusive_process:mps=yes"
#BSUB -R "rusage[mem=7GB]"
#BSUB -W 5

module load cuda/10.2
module load gcc/6.3.0

# define the driver name to use
# valid values: matmult_c.studio, matmult_f.studio, matmult_c.gcc or
# matmult_f.gcc
#
EXECUTABLE=matmult_f.nvcc

# define the mkn values in the MKN variable
#
SIZES="500 1000 2000 4000 8000"

# define the permutation type in PERM
#
PERM="gpu5"

# uncomment and set a reasonable BLKSIZE for the blk version
#
# BLKSIZE=1

# enable(1)/disable(0) result checking
export MATMULT_COMPARE=0

# start the collect command with the above settings
for S in $SIZES
do
    MATMULT_COMPARE=0 nvprof --print-gpu-summary ./$EXECUTABLE $PERM $S $S $S
    #ATMULT_COMPARE=0 ./$EXECUTABLE $PERM $S $S $S
done

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   21.00 sec.
    Max Memory :                                 413 MB
    Average Memory :                             413.00 MB
    Total Requested Memory :                     7168.00 MB
    Delta Memory :                               6755.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                15
    Run time :                                   45 sec.
    Turnaround time :                            26 sec.

The output (if any) is above this job summary.

